{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to Learning Robotics","title":"Welcome to Learning Robotics"},{"location":"#welcome-to-learning-robotics","text":"","title":"Welcome to Learning Robotics"},{"location":"Gazebo/","text":"Gazebo simulator Gazebo is a physics simualtor which make it easy to examine robots algorithms. Building new world In oreder to build a world or a model in the gazebo, we should create a sdf file. A world sdf file should look as: xml version sdf version world model An example to world file: <?xml version='1.0'?> <sdf version=\"1.5\"> <world name=\"default\"> <model name=\"ground_plane\"> <static>true</static> <link name=\"link\"> <collision name=\"collision\"> <geometry> <plane> <normal>0 0 1</normal> <size>100 100</size> </plane> </geometry> <surface> <contact> <collide_bitmask>0xffff</collide_bitmask> </contact> <friction> <ode> <mu>0.8</mu> <mu2>0</mu2> </ode> </friction> </surface> </collision> <visual name=\"visual\"> <cast_shadows>false</cast_shadows> <geometry> <plane> <normal>0 0 1</normal> <size>100 100</size> </plane> </geometry> <material> <script> <uri>file://media/materials/scripts/gazebo.material</uri> <name>Gazebo/Grey</name> </script> </material> </visual> </link> </model> <model name ='box'> <pose>1 2 0 0 0 0</pose> <link name ='link'> <pose>0 0 .5 0 0 0</pose> <collision name ='collision'> <geometry> <box><size>1 1 1</size></box> </geometry> </collision> <visual name ='visual'> <geometry> <box><size>1 1 1</size></box> </geometry> </visual> </link> </model> </world> </sdf> If you want to add a color to your model, you should add material to the visual tag: <material> <script> <uri>file://media/materials/scripts/gazebo.material<uri> <name>Gazebo/Green</name> </script> </material>","title":"Gazebo simulator"},{"location":"Gazebo/#gazebo-simulator","text":"Gazebo is a physics simualtor which make it easy to examine robots algorithms.","title":"Gazebo simulator"},{"location":"Gazebo/#building-new-world","text":"In oreder to build a world or a model in the gazebo, we should create a sdf file. A world sdf file should look as: xml version sdf version world model An example to world file: <?xml version='1.0'?> <sdf version=\"1.5\"> <world name=\"default\"> <model name=\"ground_plane\"> <static>true</static> <link name=\"link\"> <collision name=\"collision\"> <geometry> <plane> <normal>0 0 1</normal> <size>100 100</size> </plane> </geometry> <surface> <contact> <collide_bitmask>0xffff</collide_bitmask> </contact> <friction> <ode> <mu>0.8</mu> <mu2>0</mu2> </ode> </friction> </surface> </collision> <visual name=\"visual\"> <cast_shadows>false</cast_shadows> <geometry> <plane> <normal>0 0 1</normal> <size>100 100</size> </plane> </geometry> <material> <script> <uri>file://media/materials/scripts/gazebo.material</uri> <name>Gazebo/Grey</name> </script> </material> </visual> </link> </model> <model name ='box'> <pose>1 2 0 0 0 0</pose> <link name ='link'> <pose>0 0 .5 0 0 0</pose> <collision name ='collision'> <geometry> <box><size>1 1 1</size></box> </geometry> </collision> <visual name ='visual'> <geometry> <box><size>1 1 1</size></box> </geometry> </visual> </link> </model> </world> </sdf> If you want to add a color to your model, you should add material to the visual tag: <material> <script> <uri>file://media/materials/scripts/gazebo.material<uri> <name>Gazebo/Green</name> </script> </material>","title":"Building new world"},{"location":"Gstreamer/","text":"Gstreamer Gstreamer - pipeline-based multimedia framework Installation sudo apt-get install gstreamer1.0-tools \\ gstreamer1.0-plugins-base \\ gstreamer1.0-plugins-good \\ gstreamer1.0-plugins-bad \\ gstreamer1.0-plugins-ugly \\ gstreamer1.0-gtk3 \\ gstreamer1.0-doc \\ gstreamer1.0-tools sudo apt-get install libcairo2-dev libjpeg-dev libgif-dev libgirepository1.0-dev gir1.2-gtk-3.0 pip3 install pycairo pip3 install GObject pip3 install pygobject Check video device You can use v4l2-ctl application in order to control the linux4video devices. Example for checking camera resolution: sudo apt-get install v4l-utils v4l2-ctl -d /dev/video0 --list-formats-ext Pipes for example stream MJPG camera with compositor gst-launch-1.0 compositor name=comp \\ sink_0::xpos=0 sink_0::ypos=0 sink_0::width=320 sink_0::height=480 \\ sink_1::xpos=320 sink_1::ypos=0 sink_1::width=320 sink_1::height=480 ! autovideosink \\ v4l2src device=\"/dev/video0\" name=cam0 ! capsfilter name=capssrc0 \\ caps=image/jpeg,width=640,height=480,framerate=30/1 ! jpegdec ! videoconvert ! \\ video/x-raw,width=640,height=480 ! tee name=video_tee ! queue ! comp. \\ video_tee. ! videoscale ! video/x-raw ! comp. Dynamic compositor streaming Here is an example python code for adding video camera to a compositor and removing it. import sys import gi gi.require_version('Gst', '1.0') from gi.repository import Gst, GLib class ProbeTest: def __init__(self): # Initialize gstreamer Gst.init(sys.argv) # Define pipeline gst_str = \"\"\" compositor name=comp sink_0::xpos=0 sink_0::ypos=0 sink_0::width=320 sink_0::height=480 sink_1::xpos=320 sink_1::ypos=0 sink_1::width=320 sink_1::height=480 ! videorate ! video/x-raw,framerate=30/1 ! autovideosink videotestsrc pattern=ball is-live=True ! video/x-raw,framerate=30/1 ! queue ! comp. videotestsrc pattern=snow is-live=True ! video/x-raw,framerate=30/1 ! comp. \"\"\" # Create the pipeline self.loop = GLib.MainLoop() self.pipeline = Gst.parse_launch(gst_str) self.bus = self.pipeline.get_bus() self.bus.add_signal_watch() self.bus.connect(\"message\", self._on_message) # prepare source objects self.new_source = Gst.ElementFactory.make(\"v4l2src\", \"video0\") self.new_source.set_property('device', '/dev/video0') self.new_sourcepad = self.new_source.get_static_pad(\"src\") self.new_source_probe = self.new_sourcepad.add_probe(Gst.PadProbeType.BLOCK_DOWNSTREAM, self.modify_pipeline) # add new source to the pipeline self.pipeline.add(self.new_source) print(\"added new source to pipeline\") # prepare source caps objects self.new_capssrc = Gst.ElementFactory.make(\"capsfilter\", \"new_capssrc\") self.new_capssrc.set_property('caps', Gst.Caps.from_string(\"image/jpeg,width=640,height=480,framerate=30/1\")) self.new_jpegdec = Gst.ElementFactory.make(\"jpegdec\", \"new_jpegdec\") self.new_videoconvert = Gst.ElementFactory.make(\"videoconvert\", \"new_videoconvert\") self.new_capssrc2 = Gst.ElementFactory.make(\"capsfilter\", \"new_capssrc2\") self.new_capssrc2.set_property('caps', Gst.Caps.from_string(\"video/x-raw,width=640,height=480\")) self.new_queue = Gst.ElementFactory.make(\"queue\", \"new_queue\") self.new_queue_pad = self.new_queue.get_static_pad(\"src\") self.comp = self.pipeline.get_by_name('comp') # get compositor element from pipeline # Start the pipeline self.pipeline.set_state(Gst.State.READY) self.pipeline.set_state(Gst.State.PLAYING) def change_source(self, line): if line==\"1\\n\": self.new_comp_sink_pad = self.comp.get_request_pad(\"sink_2\") # create new compositor pad print(self.new_comp_sink_pad.name) # add new source elements to the pipeline self.pipeline.add(self.new_capssrc) self.pipeline.add(self.new_jpegdec) self.pipeline.add(self.new_videoconvert) self.pipeline.add(self.new_capssrc2) self.pipeline.add(self.new_queue) # set the source caps to ready and playing self.new_capssrc.set_state(Gst.State.READY) self.new_jpegdec.set_state(Gst.State.READY) self.new_videoconvert.set_state(Gst.State.READY) self.new_capssrc2.set_state(Gst.State.READY) self.new_queue.set_state(Gst.State.READY) self.new_capssrc.set_state(Gst.State.PLAYING) self.new_jpegdec.set_state(Gst.State.PLAYING) self.new_videoconvert.set_state(Gst.State.PLAYING) self.new_capssrc2.set_state(Gst.State.PLAYING) self.new_queue.set_state(Gst.State.PLAYING) # change the old compositor sink pads according to new properties self.comp_sink_pad0 = self.comp.get_static_pad(\"sink_0\") self.comp_sink_pad0.set_property(\"height\",240) self.comp_sink_pad1 = self.comp.get_static_pad(\"sink_1\") self.comp_sink_pad1.set_property(\"height\",240) # set the properties for the new compositor pad self.new_comp_sink_pad.set_property(\"xpos\",0) self.new_comp_sink_pad.set_property(\"ypos\",240) self.new_comp_sink_pad.set_property(\"width\",640) self.new_comp_sink_pad.set_property(\"height\",240) # link the new source : source--> caps(mjpg)--> jpegdec--> videoconvert--> caps(x/raw)--> queue self.new_source.link(self.new_capssrc) self.new_capssrc.link(self.new_jpegdec) self.new_jpegdec.link(self.new_videoconvert) self.new_videoconvert.link(self.new_capssrc2) self.new_capssrc2.link(self.new_queue) self.new_queue_pad.link(self.new_comp_sink_pad) self.new_sourcepad.remove_probe(self.new_source_probe) if line==\"2\\n\": if self.new_queue_pad.is_linked(): # check if the source pad is already exist. if not, there is nothing to remove self.new_source_probe = self.new_sourcepad.add_probe(Gst.PadProbeType.BLOCK_DOWNSTREAM, self.modify_pipeline) print(\"added source probe\") self.new_comp_sink_pad = self.new_queue_pad.get_peer() self.new_queue_pad.unlink(self.new_comp_sink_pad) # unlink the new source pad from the compositor pad # stop the caps elements of the source self.new_capssrc.set_state(Gst.State.NULL) self.new_jpegdec.set_state(Gst.State.NULL) self.new_videoconvert.set_state(Gst.State.NULL) self.new_capssrc2.set_state(Gst.State.NULL) self.new_queue.set_state(Gst.State.NULL) # remove the caps elements of the source from pipeline self.new_capssrc.get_parent().remove(self.new_capssrc) self.new_jpegdec.get_parent().remove(self.new_jpegdec) self.new_videoconvert.get_parent().remove(self.new_videoconvert) self.new_capssrc2.get_parent().remove(self.new_capssrc2) self.new_queue.get_parent().remove(self.new_queue) # remove the new pad from the compositor self.comp.remove_pad(self.new_comp_sink_pad) def modify_pipeline(self, pad, info): print(\"pad_blocked\") return Gst.PadProbeReturn.OK def _on_message(self, bus, message): mtype = message.type print(\"ErrorType: \" + str(mtype)) def stdin_cb(self, source, condition): print(\"stdin\") line = source.readline() print(\"line is: {}\".format(line)) self.change_source(line) return True def main(): probeTest = ProbeTest() try: GLib.io_add_watch(sys.stdin, GLib.IO_IN, probeTest.stdin_cb) probeTest.loop.run() except KeyboardInterrupt: probeTest.pipeline.set_state(Gst.State.NULL) probeTest.loop.quit() exit(0) if __name__ =='__main__': sys.exit(main()) Pipeline with factory There are two ways to create a pipeline. The first one, as showed in the example above (Dynamic compositor streaming) with parse_launch and the second with factory . Here I will present an example for creating pipeline with factory: import sys import gi gi.require_version('Gst', '1.0') from gi.repository import Gst, GLib import traceback # Initialize gstreamer Gst.init(sys.argv) def on_message(bus: Gst.Bus, message: Gst.Message, loop: GLib.MainLoop): mtype = message.type if mtype == Gst.MessageType.EOS: print(\"End of stream\") loop.quit() elif mtype == Gst.MessageType.ERROR: err, debug = message.parse_error() print(err, debug) loop.quit() elif mtype == Gst.MessageType.WARNING: err, debug = message.parse_warning() print(err, debug) return True pipeline = Gst.Pipeline() # Creates element by name src = Gst.ElementFactory.make(\"videotestsrc\", \"videotestsrc_name\") src.set_property(\"num-buffers\", 50) src.set_property(\"pattern\", \"ball\") sink = Gst.ElementFactory.make(\"autovideosink\") pipeline.add(src) # add elements to the pipeline pipeline.add(sink) src.link(sink) # link the elements bus = pipeline.get_bus() # Start pipeline pipeline.set_state(Gst.State.PLAYING) # Init GObject loop to handle Gstreamer Bus Events loop = GLib.MainLoop() bus.add_signal_watch() # allow bus to emit messages to main thread bus.connect(\"message\", on_message, loop) # Add handler to specific signal try: loop.run() except Exception: traceback.print_exc() loop.quit() # Stop Pipeline pipeline.set_state(Gst.State.NULL) del pipeline","title":"Gstreamer"},{"location":"Gstreamer/#gstreamer","text":"Gstreamer - pipeline-based multimedia framework","title":"Gstreamer"},{"location":"Gstreamer/#installation","text":"sudo apt-get install gstreamer1.0-tools \\ gstreamer1.0-plugins-base \\ gstreamer1.0-plugins-good \\ gstreamer1.0-plugins-bad \\ gstreamer1.0-plugins-ugly \\ gstreamer1.0-gtk3 \\ gstreamer1.0-doc \\ gstreamer1.0-tools sudo apt-get install libcairo2-dev libjpeg-dev libgif-dev libgirepository1.0-dev gir1.2-gtk-3.0 pip3 install pycairo pip3 install GObject pip3 install pygobject","title":"Installation"},{"location":"Gstreamer/#check-video-device","text":"You can use v4l2-ctl application in order to control the linux4video devices. Example for checking camera resolution: sudo apt-get install v4l-utils v4l2-ctl -d /dev/video0 --list-formats-ext","title":"Check video device"},{"location":"Gstreamer/#pipes-for-example","text":"","title":"Pipes for example"},{"location":"Gstreamer/#stream-mjpg-camera-with-compositor","text":"gst-launch-1.0 compositor name=comp \\ sink_0::xpos=0 sink_0::ypos=0 sink_0::width=320 sink_0::height=480 \\ sink_1::xpos=320 sink_1::ypos=0 sink_1::width=320 sink_1::height=480 ! autovideosink \\ v4l2src device=\"/dev/video0\" name=cam0 ! capsfilter name=capssrc0 \\ caps=image/jpeg,width=640,height=480,framerate=30/1 ! jpegdec ! videoconvert ! \\ video/x-raw,width=640,height=480 ! tee name=video_tee ! queue ! comp. \\ video_tee. ! videoscale ! video/x-raw ! comp.","title":"stream MJPG camera with compositor"},{"location":"Gstreamer/#dynamic-compositor-streaming","text":"Here is an example python code for adding video camera to a compositor and removing it. import sys import gi gi.require_version('Gst', '1.0') from gi.repository import Gst, GLib class ProbeTest: def __init__(self): # Initialize gstreamer Gst.init(sys.argv) # Define pipeline gst_str = \"\"\" compositor name=comp sink_0::xpos=0 sink_0::ypos=0 sink_0::width=320 sink_0::height=480 sink_1::xpos=320 sink_1::ypos=0 sink_1::width=320 sink_1::height=480 ! videorate ! video/x-raw,framerate=30/1 ! autovideosink videotestsrc pattern=ball is-live=True ! video/x-raw,framerate=30/1 ! queue ! comp. videotestsrc pattern=snow is-live=True ! video/x-raw,framerate=30/1 ! comp. \"\"\" # Create the pipeline self.loop = GLib.MainLoop() self.pipeline = Gst.parse_launch(gst_str) self.bus = self.pipeline.get_bus() self.bus.add_signal_watch() self.bus.connect(\"message\", self._on_message) # prepare source objects self.new_source = Gst.ElementFactory.make(\"v4l2src\", \"video0\") self.new_source.set_property('device', '/dev/video0') self.new_sourcepad = self.new_source.get_static_pad(\"src\") self.new_source_probe = self.new_sourcepad.add_probe(Gst.PadProbeType.BLOCK_DOWNSTREAM, self.modify_pipeline) # add new source to the pipeline self.pipeline.add(self.new_source) print(\"added new source to pipeline\") # prepare source caps objects self.new_capssrc = Gst.ElementFactory.make(\"capsfilter\", \"new_capssrc\") self.new_capssrc.set_property('caps', Gst.Caps.from_string(\"image/jpeg,width=640,height=480,framerate=30/1\")) self.new_jpegdec = Gst.ElementFactory.make(\"jpegdec\", \"new_jpegdec\") self.new_videoconvert = Gst.ElementFactory.make(\"videoconvert\", \"new_videoconvert\") self.new_capssrc2 = Gst.ElementFactory.make(\"capsfilter\", \"new_capssrc2\") self.new_capssrc2.set_property('caps', Gst.Caps.from_string(\"video/x-raw,width=640,height=480\")) self.new_queue = Gst.ElementFactory.make(\"queue\", \"new_queue\") self.new_queue_pad = self.new_queue.get_static_pad(\"src\") self.comp = self.pipeline.get_by_name('comp') # get compositor element from pipeline # Start the pipeline self.pipeline.set_state(Gst.State.READY) self.pipeline.set_state(Gst.State.PLAYING) def change_source(self, line): if line==\"1\\n\": self.new_comp_sink_pad = self.comp.get_request_pad(\"sink_2\") # create new compositor pad print(self.new_comp_sink_pad.name) # add new source elements to the pipeline self.pipeline.add(self.new_capssrc) self.pipeline.add(self.new_jpegdec) self.pipeline.add(self.new_videoconvert) self.pipeline.add(self.new_capssrc2) self.pipeline.add(self.new_queue) # set the source caps to ready and playing self.new_capssrc.set_state(Gst.State.READY) self.new_jpegdec.set_state(Gst.State.READY) self.new_videoconvert.set_state(Gst.State.READY) self.new_capssrc2.set_state(Gst.State.READY) self.new_queue.set_state(Gst.State.READY) self.new_capssrc.set_state(Gst.State.PLAYING) self.new_jpegdec.set_state(Gst.State.PLAYING) self.new_videoconvert.set_state(Gst.State.PLAYING) self.new_capssrc2.set_state(Gst.State.PLAYING) self.new_queue.set_state(Gst.State.PLAYING) # change the old compositor sink pads according to new properties self.comp_sink_pad0 = self.comp.get_static_pad(\"sink_0\") self.comp_sink_pad0.set_property(\"height\",240) self.comp_sink_pad1 = self.comp.get_static_pad(\"sink_1\") self.comp_sink_pad1.set_property(\"height\",240) # set the properties for the new compositor pad self.new_comp_sink_pad.set_property(\"xpos\",0) self.new_comp_sink_pad.set_property(\"ypos\",240) self.new_comp_sink_pad.set_property(\"width\",640) self.new_comp_sink_pad.set_property(\"height\",240) # link the new source : source--> caps(mjpg)--> jpegdec--> videoconvert--> caps(x/raw)--> queue self.new_source.link(self.new_capssrc) self.new_capssrc.link(self.new_jpegdec) self.new_jpegdec.link(self.new_videoconvert) self.new_videoconvert.link(self.new_capssrc2) self.new_capssrc2.link(self.new_queue) self.new_queue_pad.link(self.new_comp_sink_pad) self.new_sourcepad.remove_probe(self.new_source_probe) if line==\"2\\n\": if self.new_queue_pad.is_linked(): # check if the source pad is already exist. if not, there is nothing to remove self.new_source_probe = self.new_sourcepad.add_probe(Gst.PadProbeType.BLOCK_DOWNSTREAM, self.modify_pipeline) print(\"added source probe\") self.new_comp_sink_pad = self.new_queue_pad.get_peer() self.new_queue_pad.unlink(self.new_comp_sink_pad) # unlink the new source pad from the compositor pad # stop the caps elements of the source self.new_capssrc.set_state(Gst.State.NULL) self.new_jpegdec.set_state(Gst.State.NULL) self.new_videoconvert.set_state(Gst.State.NULL) self.new_capssrc2.set_state(Gst.State.NULL) self.new_queue.set_state(Gst.State.NULL) # remove the caps elements of the source from pipeline self.new_capssrc.get_parent().remove(self.new_capssrc) self.new_jpegdec.get_parent().remove(self.new_jpegdec) self.new_videoconvert.get_parent().remove(self.new_videoconvert) self.new_capssrc2.get_parent().remove(self.new_capssrc2) self.new_queue.get_parent().remove(self.new_queue) # remove the new pad from the compositor self.comp.remove_pad(self.new_comp_sink_pad) def modify_pipeline(self, pad, info): print(\"pad_blocked\") return Gst.PadProbeReturn.OK def _on_message(self, bus, message): mtype = message.type print(\"ErrorType: \" + str(mtype)) def stdin_cb(self, source, condition): print(\"stdin\") line = source.readline() print(\"line is: {}\".format(line)) self.change_source(line) return True def main(): probeTest = ProbeTest() try: GLib.io_add_watch(sys.stdin, GLib.IO_IN, probeTest.stdin_cb) probeTest.loop.run() except KeyboardInterrupt: probeTest.pipeline.set_state(Gst.State.NULL) probeTest.loop.quit() exit(0) if __name__ =='__main__': sys.exit(main())","title":"Dynamic compositor streaming"},{"location":"Gstreamer/#pipeline-with-factory","text":"There are two ways to create a pipeline. The first one, as showed in the example above (Dynamic compositor streaming) with parse_launch and the second with factory . Here I will present an example for creating pipeline with factory: import sys import gi gi.require_version('Gst', '1.0') from gi.repository import Gst, GLib import traceback # Initialize gstreamer Gst.init(sys.argv) def on_message(bus: Gst.Bus, message: Gst.Message, loop: GLib.MainLoop): mtype = message.type if mtype == Gst.MessageType.EOS: print(\"End of stream\") loop.quit() elif mtype == Gst.MessageType.ERROR: err, debug = message.parse_error() print(err, debug) loop.quit() elif mtype == Gst.MessageType.WARNING: err, debug = message.parse_warning() print(err, debug) return True pipeline = Gst.Pipeline() # Creates element by name src = Gst.ElementFactory.make(\"videotestsrc\", \"videotestsrc_name\") src.set_property(\"num-buffers\", 50) src.set_property(\"pattern\", \"ball\") sink = Gst.ElementFactory.make(\"autovideosink\") pipeline.add(src) # add elements to the pipeline pipeline.add(sink) src.link(sink) # link the elements bus = pipeline.get_bus() # Start pipeline pipeline.set_state(Gst.State.PLAYING) # Init GObject loop to handle Gstreamer Bus Events loop = GLib.MainLoop() bus.add_signal_watch() # allow bus to emit messages to main thread bus.connect(\"message\", on_message, loop) # Add handler to specific signal try: loop.run() except Exception: traceback.print_exc() loop.quit() # Stop Pipeline pipeline.set_state(Gst.State.NULL) del pipeline","title":"Pipeline with factory"},{"location":"Ubuntu_cheat_sheet/","text":"Ubuntu cheat sheet Command Explanation man sed get manual of a command, for example sed command ps -aux grep lspci check GPU version lsb_release -a check ubuntu version grep -r \"word\" /path/to/files find a word inside all files uptime check computer running time dmesg show usb connections find . -iname find a file which find the file path chown -Rfv user:user /tmp change user and group owner of /tmp (or any folder/file) df -h show the free disk (-h= human readable, -a= all, even if the disk is 0) sudo tcpdump -n -i lo check connections (-n= no resolve, lo= local card, protocol_name= arp,icmp etc) for example: sudo tcpdump -n -i any icmp = check connection for any card Installations Command Explanation dpkg -l grep dpkg -i .deb install deb file cat /etc/apt/sources.list get link to all ubuntu installations and network deb files cat /etc/hosts file for changing IP and for adding external server machine Networks Command Explanation ifconfig check my IP ip addr see all IP addresses, as ifconfig sudo ifconfig eth0:1 /24 add virtual IP address. 24 is for subnet 255.255.255.0 netstat -nau check udp processes netstat -naup check udp processes with details netstat -natp check tcp processes arp -n check connection history Open a file Command Explanation code open visual studio code IDE vim terminal with edit option less terminal - show content one page at a time cat terminal short view","title":"Ubuntu cheat sheet"},{"location":"Ubuntu_cheat_sheet/#ubuntu-cheat-sheet","text":"Command Explanation man sed get manual of a command, for example sed command ps -aux grep lspci check GPU version lsb_release -a check ubuntu version grep -r \"word\" /path/to/files find a word inside all files uptime check computer running time dmesg show usb connections find . -iname find a file which find the file path chown -Rfv user:user /tmp change user and group owner of /tmp (or any folder/file) df -h show the free disk (-h= human readable, -a= all, even if the disk is 0) sudo tcpdump -n -i lo check connections (-n= no resolve, lo= local card, protocol_name= arp,icmp etc) for example: sudo tcpdump -n -i any icmp = check connection for any card","title":"Ubuntu cheat sheet"},{"location":"Ubuntu_cheat_sheet/#installations","text":"Command Explanation dpkg -l grep dpkg -i .deb install deb file cat /etc/apt/sources.list get link to all ubuntu installations and network deb files cat /etc/hosts file for changing IP and for adding external server machine","title":"Installations"},{"location":"Ubuntu_cheat_sheet/#networks","text":"Command Explanation ifconfig check my IP ip addr see all IP addresses, as ifconfig sudo ifconfig eth0:1 /24 add virtual IP address. 24 is for subnet 255.255.255.0 netstat -nau check udp processes netstat -naup check udp processes with details netstat -natp check tcp processes arp -n check connection history","title":"Networks"},{"location":"Ubuntu_cheat_sheet/#open-a-file","text":"Command Explanation code open visual studio code IDE vim terminal with edit option less terminal - show content one page at a time cat terminal short view","title":"Open a file"},{"location":"apt-cacher-ng/","text":"Apt cacher ng It is a package to create a local cache of the Debian mirrors. Server To get started you should create a server by installing the package: apt install apt-cacher-ng change the cache directory in the configuration file: vim /etc/apt-cacher-ng/acng.conf In the line of CacheDir choose your directory path. Client Define the client configuration in order to know about the proxy: echo 'Acquire::http { Proxy \"http://<server_ip>:3142\"; }' | sudo tee -a /etc/apt/apt.conf.d/proxy Check your cacher: In the client machine: sudo apt update sudo apt install <package_name> you should be able to see the files in the server machine (according to CacheDir in the acng.conf file).","title":"Apt cacher ng"},{"location":"apt-cacher-ng/#apt-cacher-ng","text":"It is a package to create a local cache of the Debian mirrors.","title":"Apt cacher ng"},{"location":"apt-cacher-ng/#server","text":"To get started you should create a server by installing the package: apt install apt-cacher-ng change the cache directory in the configuration file: vim /etc/apt-cacher-ng/acng.conf In the line of CacheDir choose your directory path.","title":"Server"},{"location":"apt-cacher-ng/#client","text":"Define the client configuration in order to know about the proxy: echo 'Acquire::http { Proxy \"http://<server_ip>:3142\"; }' | sudo tee -a /etc/apt/apt.conf.d/proxy","title":"Client"},{"location":"apt-cacher-ng/#check-your-cacher","text":"In the client machine: sudo apt update sudo apt install <package_name> you should be able to see the files in the server machine (according to CacheDir in the acng.conf file).","title":"Check your cacher:"},{"location":"aptly/","text":"Aptly When trying to update several computers in local network (without internet connection) aptly is a convinient solution. You can either create a mirror of remote repositories or build your desired repository from deb files. Aptly snapshot option allows you to transition your package environment to a new version, or rollback to a previous version. After publishing a snapshot, you can use apt tool in order to install packages. Create a key In your home directory create a GPG2 batch file: cat >~/gpg2_generate_batch_file.txt <<EOF %echo Generating a default key Key-Type: RSA Key-Length: 4096 Name-Real: MyCompanyName Name-Comment: aptly key no passphrase Name-Email: info@mycompanyname.com Expire-Date: 0 %no-protection # Do a commit here, so that we can later print \"done\" :-) %commit %echo done EOF Generate a general key: gpg --batch --gen-key ~/gpg2_generate_batch_file.txt This key will allow us to sign and export our repository. First we need to check our key: gpg --list-key The key will look as follow: gpg: checking the trustdb gpg: marginals needed: 3 completes needed: 1 trust model: pgp gpg: depth: 0 valid: 1 signed: 0 trust: 0-, 0q, 0n, 0m, 0f, 1u /home/robokal/.gnupg/pubring.kbx ------------------------------ pub rsa4096 2021-03-20 [SCEA] 152B12FDCCEB6DCD186430F56FBBF490B10AB3CB uid [ultimate] MyCompanyName (aptly key no passphrase) <info@mycompanyname.com> At last, we should export the key: gpg --output ~/.aptly/public/key.pub --armor --export 152B12FDCCEB6DCD186430F56FBBF490B10AB3CB Publish a reposiroty Create a repository: aptly repo create repo_name Add packages to your repository (for deb files): aptly repo add repo_name ~/Downloads/folder_name Create a snapshot: aptly snapshot create snap_name from repo repo_name Publish the repository, choose the component and the distribution: sudo aptly publish snapshot -component=main -distribution=focal snap_name Finally, serve the published repository: aptly serve Use the repository In other machine, you can use the published repository to install the packages. First, add the key. Insert the IP of the serve machine: wget http://192.168.1.14:8080/key.pub sudo apt-key add key.pub Check your machine keys: apt-key list Now you can update your system. Add to the file /etc/apt/sources.list (according to the desired serve IP, distribution and component): deb http://192.168.1.14:8080/ubuntu focal main At last, you can update your machine: sudo apt update sudo apt install <package_name>","title":"Aptly"},{"location":"aptly/#aptly","text":"When trying to update several computers in local network (without internet connection) aptly is a convinient solution. You can either create a mirror of remote repositories or build your desired repository from deb files. Aptly snapshot option allows you to transition your package environment to a new version, or rollback to a previous version. After publishing a snapshot, you can use apt tool in order to install packages.","title":"Aptly"},{"location":"aptly/#create-a-key","text":"In your home directory create a GPG2 batch file: cat >~/gpg2_generate_batch_file.txt <<EOF %echo Generating a default key Key-Type: RSA Key-Length: 4096 Name-Real: MyCompanyName Name-Comment: aptly key no passphrase Name-Email: info@mycompanyname.com Expire-Date: 0 %no-protection # Do a commit here, so that we can later print \"done\" :-) %commit %echo done EOF Generate a general key: gpg --batch --gen-key ~/gpg2_generate_batch_file.txt This key will allow us to sign and export our repository. First we need to check our key: gpg --list-key The key will look as follow: gpg: checking the trustdb gpg: marginals needed: 3 completes needed: 1 trust model: pgp gpg: depth: 0 valid: 1 signed: 0 trust: 0-, 0q, 0n, 0m, 0f, 1u /home/robokal/.gnupg/pubring.kbx ------------------------------ pub rsa4096 2021-03-20 [SCEA] 152B12FDCCEB6DCD186430F56FBBF490B10AB3CB uid [ultimate] MyCompanyName (aptly key no passphrase) <info@mycompanyname.com> At last, we should export the key: gpg --output ~/.aptly/public/key.pub --armor --export 152B12FDCCEB6DCD186430F56FBBF490B10AB3CB","title":"Create a key"},{"location":"aptly/#publish-a-reposiroty","text":"Create a repository: aptly repo create repo_name Add packages to your repository (for deb files): aptly repo add repo_name ~/Downloads/folder_name Create a snapshot: aptly snapshot create snap_name from repo repo_name Publish the repository, choose the component and the distribution: sudo aptly publish snapshot -component=main -distribution=focal snap_name Finally, serve the published repository: aptly serve","title":"Publish a reposiroty"},{"location":"aptly/#use-the-repository","text":"In other machine, you can use the published repository to install the packages. First, add the key. Insert the IP of the serve machine: wget http://192.168.1.14:8080/key.pub sudo apt-key add key.pub Check your machine keys: apt-key list Now you can update your system. Add to the file /etc/apt/sources.list (according to the desired serve IP, distribution and component): deb http://192.168.1.14:8080/ubuntu focal main At last, you can update your machine: sudo apt update sudo apt install <package_name>","title":"Use the repository"},{"location":"canbus/","text":"CanBus CAN = Controller Area Network Is a standardized communication protocol designed to allow microcontrollers and other devices to communicate with each other. Installation: pip install python-can pip install cantools Activation on jetson (TX2): sudo modprobe can sudo modprobe can_raw sudo modprobe mttcan sudo ip link set can0 type can bitrate 250000 restart-ms 100 loopback sudo ip link set can0 up Generate dbc file (canbus databases) The dbc file can be generated as explained in intro to dbc . Using a program named Kvaser Database editor, you can create a simple dbc file according to your own messages protocol. An easy explanation can be found here Simple example - my_cam.dbc: VERSION \"\" NS_ : CM_ BA_DEF_ BA_ BA_DEF_DEF_ BS_: BU_: BO_ 50 TEST: 8 Vector_XXX SG_ ThrottleSpeed : 0|8@1+ (0.125,0) [0|0] \"rpm_precent\" Vector_XXX BO_ 2566844926 CCVS1: 8 Vector_XXX SG_ WheelBasedVehicleSpeed : 8|16@1+ (0.00390625,0) [0|250.996] \"km/h\" Vector_XXX CM_ BO_ 50 \"Electronic Engine Controller 1\"; CM_ SG_ 50 ThrottleSpeed \"Actual engine speed\" Communication - send and receive can messages Example - save as can_node.py import sys import os import can from can.bus import BusState from threading import Thread, Event import logging import cantools import time log = logging.getLogger(__name__) class CanNode: def __init__(self,db): self.db = db def send_encoded_message(self, bus, stop_event): \"\"\"loop for sending encoded can messages\"\"\" log.warn(\"Start sending a message every 1s\") start_time = time.time() while not stop_event.is_set(): throttle_message = self.db.get_message_by_name('TEST') data = throttle_message.encode({'ThrottleSpeed': 10}) msg = can.Message(arbitration_id = throttle_message. frame_id, data = data, timestamp = time.time() - start_time) bus.send(msg) log.warn(\"tx: {}\".format(msg)) time.sleep(1) log.warn(\"Stop sending messages) def receive_encoded_message(self, bus, stop_event) \"\"\"loop for receiving\"\"\" log.warn(\"Start receiving can messages\") while not stop_event.is_set(): rx_msg = bus.recv(1) if rx_msg is not None: log.warn(\"rx: {}\".format(rx_msg)) log.warn(\"decoded: {}\".format(self.db.decode_message(rx_msg.arbitration_id, rx_msg.data))) log.warn(\"Stop receiving messages\") def main(): db = cantools.database.load_file('my_can.dbc') can_node = CanNode(db) with can.interface.Bus(bustype='socketcan', channel='can0', bitrate=250000) as bus: stop_event = Event() send_cyclic_thread = Thread(target = can_node.send_encoded_message, args=(bus, stop_event)) receive_thread = Thread(target = can_node.receive_encoded_message, args=(bus, stop_event)) send_cyclic_thread.start() receive_thread.start() try: while True: time.sleep(0) except KeyboardInterrupt: stop_event.set() time.sleep(0.5) exit(0) if __name__=='__main__': sys.exit(main())","title":"CanBus"},{"location":"canbus/#canbus","text":"CAN = Controller Area Network Is a standardized communication protocol designed to allow microcontrollers and other devices to communicate with each other.","title":"CanBus"},{"location":"canbus/#installation","text":"pip install python-can pip install cantools","title":"Installation:"},{"location":"canbus/#activation-on-jetson-tx2","text":"sudo modprobe can sudo modprobe can_raw sudo modprobe mttcan sudo ip link set can0 type can bitrate 250000 restart-ms 100 loopback sudo ip link set can0 up","title":"Activation on jetson (TX2):"},{"location":"canbus/#generate-dbc-file-canbus-databases","text":"The dbc file can be generated as explained in intro to dbc . Using a program named Kvaser Database editor, you can create a simple dbc file according to your own messages protocol. An easy explanation can be found here Simple example - my_cam.dbc: VERSION \"\" NS_ : CM_ BA_DEF_ BA_ BA_DEF_DEF_ BS_: BU_: BO_ 50 TEST: 8 Vector_XXX SG_ ThrottleSpeed : 0|8@1+ (0.125,0) [0|0] \"rpm_precent\" Vector_XXX BO_ 2566844926 CCVS1: 8 Vector_XXX SG_ WheelBasedVehicleSpeed : 8|16@1+ (0.00390625,0) [0|250.996] \"km/h\" Vector_XXX CM_ BO_ 50 \"Electronic Engine Controller 1\"; CM_ SG_ 50 ThrottleSpeed \"Actual engine speed\"","title":"Generate dbc file (canbus databases)"},{"location":"canbus/#communication-send-and-receive-can-messages","text":"Example - save as can_node.py import sys import os import can from can.bus import BusState from threading import Thread, Event import logging import cantools import time log = logging.getLogger(__name__) class CanNode: def __init__(self,db): self.db = db def send_encoded_message(self, bus, stop_event): \"\"\"loop for sending encoded can messages\"\"\" log.warn(\"Start sending a message every 1s\") start_time = time.time() while not stop_event.is_set(): throttle_message = self.db.get_message_by_name('TEST') data = throttle_message.encode({'ThrottleSpeed': 10}) msg = can.Message(arbitration_id = throttle_message. frame_id, data = data, timestamp = time.time() - start_time) bus.send(msg) log.warn(\"tx: {}\".format(msg)) time.sleep(1) log.warn(\"Stop sending messages) def receive_encoded_message(self, bus, stop_event) \"\"\"loop for receiving\"\"\" log.warn(\"Start receiving can messages\") while not stop_event.is_set(): rx_msg = bus.recv(1) if rx_msg is not None: log.warn(\"rx: {}\".format(rx_msg)) log.warn(\"decoded: {}\".format(self.db.decode_message(rx_msg.arbitration_id, rx_msg.data))) log.warn(\"Stop receiving messages\") def main(): db = cantools.database.load_file('my_can.dbc') can_node = CanNode(db) with can.interface.Bus(bustype='socketcan', channel='can0', bitrate=250000) as bus: stop_event = Event() send_cyclic_thread = Thread(target = can_node.send_encoded_message, args=(bus, stop_event)) receive_thread = Thread(target = can_node.receive_encoded_message, args=(bus, stop_event)) send_cyclic_thread.start() receive_thread.start() try: while True: time.sleep(0) except KeyboardInterrupt: stop_event.set() time.sleep(0.5) exit(0) if __name__=='__main__': sys.exit(main())","title":"Communication - send and receive can messages"},{"location":"mkdocs/","text":"Mkdocs MkDocs is a fastand simple static site generator which can help you build your project documentation. Documentation source files are written in Markdown, and configured with a single YAML configuration file. Installation Install with pip: pip install mkdocs Create file mkdocs.yml in your project: site_name: <your_site_name> Try to see your site: run with -v to present errors if occure mkdocs -v serve Run: http://127.0.0.1:8000 Plugins search plugin should call once. It is a default plugin and if you declare plugins you should declare search. Create Table In your MarkDown file, create a table as: | First Column | Second Column | Third Column | |---------------|:--------------:|---------------| | Ex1 | Ex2 | Ex3 | In order to center the content, use :---: as shown in Second Column Install the plugin: pip install mkdocs-bootstrap-tables-plugin Add the plugin to mkdocs.yml file: plugins: - search - bootstrap-tables You will get the table as displayed: First Column Second Column Third Column Ex1 Ex2 Ex3 Create Mermaid Graphs In your MarkDown file, create an example graph: graph LR Hello --> MermaidPlugin Install the plugin: pip install mkdocs-mermaid2-plugin Enter to https://www.cdnpkg.com/mermaid/file/mermaid.min.js/ and download the file mermaid.min.js (version 8.6.3) Save the file on project/docs folder. Add the plugin to mkdocs.yml file: plugins: - search - mermaid2 Add the Mermaid library declaration to mkdocs.yml file: extra_javascript: - mermaid.min.js Download from vscode MarketPlace the Markdown Preview Mermaid Support in order to see mermaid graphs on markdown file. Code Reference Install the plugin: pip install mkdocstrings Add the plugin to mkdocs.yml file: plugins: - search - mkdocstrings Add a reference in your MarkDown file: ::: <folder>.<file_name>.<class/function> For example: ::: src.main.func","title":"Mkdocs"},{"location":"mkdocs/#mkdocs","text":"MkDocs is a fastand simple static site generator which can help you build your project documentation. Documentation source files are written in Markdown, and configured with a single YAML configuration file.","title":"Mkdocs"},{"location":"mkdocs/#installation","text":"Install with pip: pip install mkdocs Create file mkdocs.yml in your project: site_name: <your_site_name> Try to see your site: run with -v to present errors if occure mkdocs -v serve Run: http://127.0.0.1:8000","title":"Installation"},{"location":"mkdocs/#plugins","text":"search plugin should call once. It is a default plugin and if you declare plugins you should declare search.","title":"Plugins"},{"location":"mkdocs/#create-table","text":"In your MarkDown file, create a table as: | First Column | Second Column | Third Column | |---------------|:--------------:|---------------| | Ex1 | Ex2 | Ex3 | In order to center the content, use :---: as shown in Second Column Install the plugin: pip install mkdocs-bootstrap-tables-plugin Add the plugin to mkdocs.yml file: plugins: - search - bootstrap-tables You will get the table as displayed: First Column Second Column Third Column Ex1 Ex2 Ex3","title":"Create Table"},{"location":"mkdocs/#create-mermaid-graphs","text":"In your MarkDown file, create an example graph: graph LR Hello --> MermaidPlugin Install the plugin: pip install mkdocs-mermaid2-plugin Enter to https://www.cdnpkg.com/mermaid/file/mermaid.min.js/ and download the file mermaid.min.js (version 8.6.3) Save the file on project/docs folder. Add the plugin to mkdocs.yml file: plugins: - search - mermaid2 Add the Mermaid library declaration to mkdocs.yml file: extra_javascript: - mermaid.min.js Download from vscode MarketPlace the Markdown Preview Mermaid Support in order to see mermaid graphs on markdown file.","title":"Create Mermaid Graphs"},{"location":"mkdocs/#code-reference","text":"Install the plugin: pip install mkdocstrings Add the plugin to mkdocs.yml file: plugins: - search - mkdocstrings Add a reference in your MarkDown file: ::: <folder>.<file_name>.<class/function> For example: ::: src.main.func","title":"Code Reference"}]}